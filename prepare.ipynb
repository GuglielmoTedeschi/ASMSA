{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6851ea37",
   "metadata": {},
   "source": [
    "# ASMSA: Prepare and check input files\n",
    "\n",
    "**Next steps**\n",
    "- [tune.ipynb](tune.ipynb): Perform initial hyperparameter tuning for this molecule\n",
    "- [train.ipynb](train.ipynb): Use results of previous tuning in more thorough training\n",
    "- [md.ipynb](md.ipynb): Use a trained model in MD simulation with Gromacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b70ab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdtraj as md\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import asmsa\n",
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import gromacs as gmx\n",
    "import gromacs.fileformats as gf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaba1b8f-d0ff-4264-9712-d06ad9ac964f",
   "metadata": {},
   "source": [
    "## Prepare input files\n",
    "\n",
    "Tryptophan cage files are downloaded in this section from our Google drive. \n",
    "\n",
    "This is for demonstration purpose, in real use the inputs should be placed here, and _conf, traj, topol, index_ variables set to their filenames names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b505da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download trpcage files\n",
    "urllib.request.urlretrieve(\"https://drive.google.com/uc?export=download&id=19RZmGgz9goXEAbreUd0OBCKWr5UAVN5d\",\"index_correct.ndx\")\n",
    "urllib.request.urlretrieve(\"https://drive.google.com/uc?export=download&id=1G-4HRnc1R-LqAArFh0DTY-e5ULd8Goly\",\"topol_correct.top\")\n",
    "urllib.request.urlretrieve(\"https://drive.google.com/uc?export=download&id=1ddOJPQxXCw3jY3Yds6bm-EwGps8ClVGQ\",\"trpcage_correct.pdb\")\n",
    "urllib.request.urlretrieve(\"https://drive.google.com/uc?export=download&id=1FRM3-bCdbesShVcyRfk0cj0ILBL1ycbb\",\"trpcage_red.xtc\")\n",
    "urllib.request.urlretrieve(\"https://drive.google.com/uc?export=download&id=1A28ik84vDhIzyHPHrL8nTxgjzOQAmzLU\",\"trpcage_correct.gro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd3c43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input files\n",
    "\n",
    "# input conformation\n",
    "#conf = \"alaninedipeptide_H.pdb\"\n",
    "conf = \"trpcage_correct.pdb\"\n",
    "\n",
    "# input trajectory\n",
    "# atom numbering must be consistent with {conf}\n",
    "\n",
    "#traj = \"alaninedipeptide_reduced.xtc\"\n",
    "traj = \"trpcage_red.xtc\"\n",
    "\n",
    "# input topology\n",
    "# expected to be produced with \n",
    "#    gmx pdb2gmx -f {conf} -p {topol} -n {index} -o {gro}\n",
    "\n",
    "# Gromacs changes atom numbering, the index file must be generated and used as well\n",
    "# gro file is used to generate inverse indexing for plumed.dat\n",
    "\n",
    "#topol = \"topol.top\"\n",
    "topol = \"topol_correct.top\"\n",
    "index = 'index_correct.ndx'\n",
    "gro = 'trpcage_correct.gro'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bad735-2917-4645-8d9b-32e0bf8bbcaf",
   "metadata": {},
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef96d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trajectory, it should report expected numbers of frames and atoms/residua\n",
    "\n",
    "tr = md.load(traj,top=conf)\n",
    "idx=tr[0].top.select(\"name CA\")\n",
    "\n",
    "# for trivial cases like Ala-Ala, where superposing on CAs fails\n",
    "#idx=tr[0].top.select(\"element != H\")\n",
    "\n",
    "tr.superpose(tr[0],atom_indices=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17683c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual check, all frames should look \"reasonable\"\n",
    "\n",
    "# Because of different conventions of numbering atoms in proteins,\n",
    "# PDB file {conf} and the trajectory {traj} can become inconsistent, and this would appear here \n",
    "# as rather weird shapes of the molecule\n",
    "\n",
    "import nglview as nv\n",
    "\n",
    "v = nv.show_mdtraj(tr)\n",
    "#v.clear()\n",
    "#v.add_representation(\"ribbon\")\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875fb6f9-d5f7-457f-8362-f6eac58889ff",
   "metadata": {},
   "source": [
    "## Split datasets\n",
    "\n",
    "Split trajectory into 3 parts. Each part will represent training, validation and testing dataset respectively. The workflow is following:\n",
    "1. Shuffle configurations in trajectory\n",
    "2. Select proportions to divide the trajectory\n",
    "3. Divide the trajectory\n",
    "4. Compute RMSD between\n",
    "   * **train x validation** trajectory and filter similar structures in train trajectory\n",
    "   * **train x test** trajectory and filter similar structures in train trajectory\n",
    "   * **test x validation** trajectory and filter similar structures in test trajectory\n",
    "5. Transform into internal coordinates\n",
    "6. Save internal coordinates as datasets which can be loaded in **train.ipynb** and **tune.ipynb** notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6439d8-3423-40a1-a98b-259e6d0b1446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the trajectory so the configurations are dispersed across all datasets\n",
    "np.random.shuffle(tr.xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d742966c-94b3-475c-aecc-0c727e10e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - set proportions for train, validation and test datasets\n",
    "# - proportions must be equal to 1 when added together\n",
    "train = .7\n",
    "validation = .15\n",
    "test = .15\n",
    "\n",
    "assert train + validation + test == .9999999999999999 or 1\n",
    "\n",
    "tr_i = len(tr) * train\n",
    "X_train = tr.slice(slice(0,int(tr_i)))\n",
    "\n",
    "va_i = len(tr) * validation\n",
    "X_validate = tr.slice(slice(int(tr_i),int(tr_i)+int(va_i)))\n",
    "\n",
    "te_i = len(tr) * test\n",
    "X_test = tr.slice(slice(int(tr_i)+int(va_i),len(tr)))\n",
    "\n",
    "X_train.xyz.shape, X_validate.xyz.shape, X_test.xyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac9c322-9427-4771-8da1-0558b834c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.save_xtc('train.xtc')\n",
    "X_validate.save_xtc('validate.xtc')\n",
    "X_test.save_xtc('test.xtc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a15fec5-5e5f-4385-b043-728b8a36fd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eventual recovery\n",
    "\"\"\"\n",
    "X_train = md.load_xtc('train.xtc',conf)\n",
    "X_validate = md.load_xtc('validate.xtc',conf)\n",
    "X_test = md.load_xtc('test.xtc',conf)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da4d0b9-1200-4fe4-a626-d2f08d0fc073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get RMSD from train trajectory compared to validation trajectory\n",
    "gmx.select(s=conf,on='backbone.ndx',select='Backbone')\n",
    "gmx.rms(s=conf,f='train.xtc',f2='validate.xtc',n='backbone.ndx',m='trainxval_rmsd.xpm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda4330f-6e2f-4ded-a555-a9a164a1a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the RMDS matrix\n",
    "txv = gf.XPM('trainxval_rmsd.xpm')\n",
    "txv.array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e0259e-f166-4d3b-8e1b-70eb2a5741ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minima per row -- for each configuration in train, how far is the nearest one from validation\n",
    "txv_min = np.min(txv.array,axis=1)\n",
    "txv_min.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fededfb-e5ce-43a3-85ea-4edec1e6c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(txv_min,bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8d6f56-05c9-4b8b-aa2d-da67e16d77a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop similar structures (to validation trajectory) in train trajectory to avoid dataset being biased\n",
    "txv_difference = 0.05\n",
    "\n",
    "train_tr = X_train[np.argwhere(txv_min > txv_difference).flat]\n",
    "train_tr.xyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f7ca04-c7fe-4df5-b9fa-bfb64118ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tr.save_xtc('tmp_train.xtc')\n",
    "#gmx.start(f\"rms -f tmp_train.xtc -f2 test.xtc -s {conf} -m trainxtest_rmsd.xpm\",wait=True,delete=True,input='4 4')\n",
    "gmx.rms(s=conf,f='tmp_train.xtc',f2='test.xtc',n='backbone.ndx',m='trainxtest_rmsd.xpm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c22d17-7bdd-4c4c-a0c1-c745ddacfe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = gf.XPM('trainxtest_rmsd.xpm')\n",
    "txt.array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2d11b6-1ffe-41bb-a1e5-29856287cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_min = np.min(txt.array,axis=1)\n",
    "txt_min.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14e533f-f83f-41ed-8d4d-c20aafc67fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(txt_min,bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17541f72-e8e5-400c-96ca-9d2372c4d3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... one more time with test trajectory & test x validation...\n",
    "txt_difference = 0.05\n",
    "\n",
    "x_train = train_tr[np.argwhere(txt_min > txt_difference).flat]\n",
    "x_train.save_xtc('x_train.xtc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b027ccef-fd97-494b-bfce-d5769762336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test x validation\n",
    "#gmx.start(f\"rms -f test.xtc -f2 validate.xtc -s {conf} -m testxvalidate_rmsd.xpm\",wait=True,delete=True,input='4 4')\n",
    "gmx.rms(f='test.xtc',f2='validate.xtc',s=conf,n='backbone.ndx',m='testxvalidate_rmsd.xpm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d995e8-361f-441c-986d-f8235efe9a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "txv = gf.XPM('testxvalidate_rmsd.xpm')\n",
    "txv.array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d986593-432f-45c6-82e9-b3f6a3dbf031",
   "metadata": {},
   "outputs": [],
   "source": [
    "txv_min = np.min(txv.array,axis=1)\n",
    "txv_min.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea949db5-9b85-4508-8e51-414992e060e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(txv_min,bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf59b4-b974-4d22-bed7-9402aa296271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... one more time with test trajectory & test x validation...\n",
    "txv_difference = 0.05\n",
    "\n",
    "x_test = X_test[np.argwhere(txv_min > txv_difference).flat]\n",
    "x_test.save_xtc('x_test.xtc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097a6ea9-58a6-47c6-a5d1-6464d53f946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get shapes of filtered trajectories that are to be used as datasets\n",
    "validate_tr = md.load('validate.xtc', top=conf)\n",
    "\n",
    "trajs = [x_train, validate_tr, x_test]\n",
    "x_train.xyz.shape, validate_tr.xyz.shape, x_test.xyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e03cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshuffle the geometries to get frame last so that we can use vectorized calculations later on\n",
    "geoms = []\n",
    "\n",
    "for i in range(len(trajs)):\n",
    "    geoms.append(np.moveaxis(trajs[i].xyz,0,-1))\n",
    "    print(geoms[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff2ff1c-4222-45c9-b650-111d4f05c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save geometries\n",
    "\n",
    "tf.data.Dataset.from_tensor_slices(geoms[0]).shuffle(2048).save('datasets/geoms/train')\n",
    "tf.data.Dataset.from_tensor_slices(geoms[1]).shuffle(2048).save('datasets/geoms/validate')\n",
    "tf.data.Dataset.from_tensor_slices(geoms[2]).shuffle(2048).save('datasets/geoms/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4902fd-e2b9-4812-8b38-59bc444d7d1a",
   "metadata": {},
   "source": [
    "### Internal coordinates computation\n",
    "\n",
    "Exercise the ASMSA library on your input. Just check everything appears to work.\n",
    "\n",
    "There are multiple options that can be combined:\n",
    "- use traditional internal coordinates (bond distances, angles, and dihedrals) or not\n",
    "- include additional distances between atoms that may not be bound to express protein folding state more directly\n",
    "   - dense (all-to-all) atom distances, feasible for very small peptides only\n",
    "   - sparse atom distances (only some pairs are chosen)\n",
    "   \n",
    "**Choose the suitable one in the cell bellow, and copy the same to [tune.ipynb](tune.ipynb) and [train.ipynb](train.ipynb)**, they must be consistent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16daa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# traditional internal coordinates (bond distances, angles, and torsions) only\n",
    "\n",
    "# mol = asmsa.Molecule(conf,topol)\n",
    "\n",
    "# internal coordinates and sparse any-any atom distances (not restricted to bonds)\n",
    "# eventually, top (and index) can be left out to use sparse distances only\n",
    "\n",
    "# in how many distances each atom should be involved in average\n",
    "density = 2 # integer in [1, n_atoms-1]\n",
    "\n",
    "mols = []\n",
    "for i in range(len(geoms)):\n",
    "    sparse_dists = asmsa.NBDistancesSparse(geoms[i].shape[0], density=density)\n",
    "    mols.append(asmsa.Molecule(pdb=conf,top=topol,ndx=index,fms=[sparse_dists]))\n",
    "\n",
    "# dense distances are feasible for very small (upto 5 residua) peptides only\n",
    "\n",
    "# dense_dists = asmsa.NBDistancesDense(geom.shape[0])\n",
    "# mol = asmsa.Molecule(pdb=conf,top=topol,ndx=index,fms=[dense_dists])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a5bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "intcoords = []\n",
    "for i in range(len(mols)):\n",
    "    intcoords.append(mols[i].intcoord(geoms[i]).T)\n",
    "    print(intcoords[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b239f0e-0cf2-42f8-a3e4-d35afe93ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[train,validate,test] = intcoords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1986bd6c-7f23-4925-bb34-9464032ab9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize training set\n",
    "train_mean = np.mean(train,axis=0)\n",
    "train -= train_mean\n",
    "train_scale = np.std(train,axis=0)\n",
    "train /= train_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a06c84-0164-4f4d-a797-ca0a85153442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize test and validation sets\n",
    "test -= train_mean\n",
    "test /= train_scale\n",
    "validate -= train_mean\n",
    "validate /= train_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9927a64-0e0b-457e-851d-156737a9c828",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save for usage in tune/train/test phase\n",
    "\n",
    "tf.data.Dataset.from_tensor_slices(train).save('datasets/intcoords/train')\n",
    "tf.data.Dataset.from_tensor_slices(validate).save('datasets/intcoords/validate')\n",
    "tf.data.Dataset.from_tensor_slices(test).save('datasets/intcoords/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6b786b-46ca-445b-a6dd-678f998b7b71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb4eee9-eb63-4fdb-9926-3c0cb3b756cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
